# backend/utils/bigquery/conversation_service.py
"""
BigQuery ëŒ€í™” ì„œë¹„ìŠ¤
ëŒ€í™” ì €ì¥/ì¡°íšŒ/ì‚­ì œ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©
"""

import os
import json
import logging
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, List
from google.cloud import bigquery
from google.cloud.exceptions import NotFound
from models import ContextBlock, BlockType

logger = logging.getLogger(__name__)

class ConversationService:
    """BigQuery ëŒ€í™” ê´€ë¦¬ ì„œë¹„ìŠ¤ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©"""
    
    def __init__(self, project_id: str, location: str = "asia-northeast3"):
        """
        ConversationService ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            location: BigQuery ë¦¬ì „
        """
        self.project_id = project_id
        self.location = location
        try:
            self.client = bigquery.Client(project=project_id, location=location)
            logger.info(f"BigQuery ConversationService ì´ˆê¸°í™” ì™„ë£Œ: {project_id}")
        except Exception as e:
            logger.error(f"BigQuery ConversationService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    

    def ensure_conversations_table_exists(self) -> Dict[str, Any]:
        """ëŒ€í™” ì €ì¥ìš© ë°ì´í„°ì…‹/í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° í•„ìš”ì‹œ ìƒì„±"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            dataset_ref = self.client.dataset(dataset_name)

            # ë°ì´í„°ì…‹ í™•ì¸/ìƒì„±
            try:
                self.client.get_dataset(dataset_ref)
                logger.debug(f"ğŸ“‚ ë°ì´í„°ì…‹ ì¡´ì¬ í™•ì¸: {dataset_name}")
            except NotFound:
                dataset = bigquery.Dataset(dataset_ref)
                dataset.location = self.location
                dataset.description = "ëŒ€í™” ì €ì¥ìš© ë°ì´í„°ì…‹"
                self.client.create_dataset(dataset)
                logger.info(f"ğŸ“‚ ë°ì´í„°ì…‹ ìë™ ìƒì„±: {dataset_name}")

            # í…Œì´ë¸” í™•ì¸/ìƒì„±
            table_ref = dataset_ref.table('conversations')
            full_table_id = f"{self.project_id}.{dataset_name}.conversations"
            try:
                self.client.get_table(table_ref)
                logger.debug(f"ğŸ“‹ ëŒ€í™” í…Œì´ë¸” ì¡´ì¬ í™•ì¸: {full_table_id}")
                return {"success": True, "action": "exists", "table_id": full_table_id}
            except NotFound:
                # ìŠ¤í‚¤ë§ˆ ì •ì˜
                schema = [
                    bigquery.SchemaField('message_id', 'STRING', mode='REQUIRED', description='ë©”ì‹œì§€ ê³ ìœ  ID'),
                    bigquery.SchemaField('user_id', 'STRING', mode='NULLABLE', description='ì‚¬ìš©ì ID'),
                    bigquery.SchemaField('message_type', 'STRING', mode='NULLABLE', description='ë©”ì‹œì§€ ìœ í˜•(user/assistant/complete)'),
                    bigquery.SchemaField('message', 'STRING', mode='NULLABLE', description='ì‚¬ìš©ì ì§ˆë¬¸ í…ìŠ¤íŠ¸'),
                    bigquery.SchemaField('response', 'STRING', mode='NULLABLE', description='AI ì‘ë‹µ í…ìŠ¤íŠ¸'),
                    bigquery.SchemaField('timestamp', 'TIMESTAMP', mode='REQUIRED', description='ìƒì„± ì‹œê° (UTC)'),
                    bigquery.SchemaField('generated_sql', 'STRING', mode='NULLABLE', description='ìƒì„±ëœ SQL'),
                    bigquery.SchemaField('query_id', 'STRING', mode='NULLABLE', description='ê²°ê³¼ì™€ ì—°ê³„ëœ ì¿¼ë¦¬ ID'),
                    bigquery.SchemaField('context_message_ids', 'STRING', mode='REPEATED', description='ì—°ê´€ ë©”ì‹œì§€ ID ë°°ì—´'),
                    bigquery.SchemaField('result_data', 'STRING', mode='NULLABLE', description='ì¿¼ë¦¬ ê²°ê³¼(JSON ì§ë ¬í™” ë¬¸ìì—´)'),
                    bigquery.SchemaField('result_row_count', 'INT64', mode='NULLABLE', description='ê²°ê³¼ í–‰ ìˆ˜'),
                    bigquery.SchemaField('result_status', 'STRING', mode='NULLABLE', description='ê²°ê³¼ ìƒíƒœ(success/error)'),
                    bigquery.SchemaField('error_message', 'STRING', mode='NULLABLE', description='ì˜¤ë¥˜ ë©”ì‹œì§€')
                ]

                table = bigquery.Table(table_ref, schema=schema)
                # ì¼ì íŒŒí‹°ì…”ë‹ ë° í´ëŸ¬ìŠ¤í„°ë§ ì ìš©
                table.time_partitioning = bigquery.TimePartitioning(
                    type_=bigquery.TimePartitioningType.DAY,
                    field='timestamp'
                )
                table.clustering_fields = ['user_id']
                table.description = 'ëŒ€í™” ë©”ì‹œì§€ ì €ì¥ í…Œì´ë¸”'

                created = self.client.create_table(table)
                logger.info(f"ğŸ“‹ ëŒ€í™” í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {created.project}.{created.dataset_id}.{created.table_id}")
                return {"success": True, "action": "created", "table_id": full_table_id}
        except Exception as e:
            logger.error(f"ëŒ€í™” í…Œì´ë¸” í™•ì¸/ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e)}

    def save_complete_interaction(self, 
                                user_id: str, 
                                user_question: str,
                                assistant_answer: str, 
                                generated_sql: str = None,
                                query_result: dict = None,
                                context_message_ids: List[str] = None) -> Dict[str, Any]:
        """ì§ˆë¬¸-ë‹µë³€-ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì €ì¥ (í†µí•© êµ¬ì¡°)"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            
            message_id = str(uuid.uuid4())
            current_time = datetime.now(timezone.utc)
            
            # í†µí•©ëœ ë°ì´í„° êµ¬ì¡° - ê³„íšì„œ ê¸°ì¤€
            interaction_data = {
                'message_id': message_id,
                'user_id': user_id,
                'message_type': 'complete',  # ì§ˆë¬¸+ë‹µë³€ ì™„ì„±í˜•
                'message': user_question,     # ì‚¬ìš©ì ì§ˆë¬¸ë§Œ
                'response': assistant_answer, # AI ì‘ë‹µë§Œ (ë³„ë„ í•„ë“œ)
                'timestamp': current_time.isoformat(),
                'generated_sql': generated_sql,
                'query_id': str(uuid.uuid4()) if query_result else None,
                'context_message_ids': context_message_ids or []
            }
            
            # ì¿¼ë¦¬ ê²°ê³¼ ì§ì ‘ í¬í•¨
            if query_result:
                # result_dataë¥¼ JSON ë¬¸ìì—´ë¡œ ëª…ì‹œì  ì§ë ¬í™”
                result_data = query_result.get('data', [])
                interaction_data.update({
                    'result_data': json.dumps(result_data) if result_data else None,
                    'result_row_count': query_result.get('row_count', 0),
                    'result_status': 'success' if query_result.get('success') else 'error',
                    'error_message': query_result.get('error')
                })
            
            # ì €ì¥ ì „ í…Œì´ë¸” í™•ì¸/ìƒì„± ë³´ì¥
            ensure = self.ensure_conversations_table_exists()
            if not ensure.get('success'):
                return {"success": False, "error": ensure.get('error', 'í…Œì´ë¸” ìƒì„± í™•ì¸ ì‹¤íŒ¨')}

            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ - ëª…ì‹œì  í…Œì´ë¸” ID ì‚¬ìš©
            table_id = f"{self.project_id}.{dataset_name}.conversations"
            try:
                table_ref = self.client.get_table(table_id)
            except NotFound:
                # ê²½í•© ìƒí™© ëŒ€ë¹„ ì¬ì‹œë„: ìƒì„± í›„ ì¦‰ì‹œ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ, í…Œì´ë¸” ë ˆí¼ëŸ°ìŠ¤ë¡œ ì¬ì‹œë„
                table_ref = self.client.dataset(dataset_name).table('conversations')
            errors = self.client.insert_rows_json(table_ref, [interaction_data])
            
            if errors:
                logger.error(f"ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì‹¤íŒ¨: {errors}")
                return {"success": False, "error": f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {errors[0]}"}
            
            logger.info(f"ğŸ’¾ ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì™„ë£Œ: {message_id}")
            return {"success": True, "message_id": message_id, "message": "ìƒí˜¸ì‘ìš©ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
            
        except Exception as e:
            logger.error(f"ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e)}




    def get_conversation_with_context(self, user_id: str, limit: int = 10) -> Dict[str, Any]:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ëª¨ë“  ëŒ€í™” ê¸°ë¡ ì¡°íšŒ - ContextBlockìœ¼ë¡œ ë°˜í™˜"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            table_id = f"{self.project_id}.{dataset_name}.conversations"
            
            query = f"""
            SELECT 
                message_id,
                message as user_question,
                response as assistant_answer,
                generated_sql,
                result_data,
                result_row_count,
                result_status,
                timestamp,
                context_message_ids
            FROM `{table_id}`
            WHERE user_id = @user_id
            ORDER BY timestamp DESC
            LIMIT @limit
            """
            
            job_config = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ScalarQueryParameter('user_id', 'STRING', user_id),
                bigquery.ScalarQueryParameter('limit', 'INT64', limit)
            ])
            
            try:
                rows = list(self.client.query(query, job_config=job_config).result())
            except Exception as e:
                if 'not found' in str(e).lower():
                    logger.info(f"í…Œì´ë¸”ì´ ì—†ìŒ. ë¹ˆ ê²°ê³¼ ë°˜í™˜: {table_id}")
                    return {"success": True, "context_blocks": [], "count": 0}
                raise
            
            context_blocks = []
            
            for row in rows:
                # result_data íŒŒì‹±
                result_data = None
                if row.result_data:
                    try:
                        result_data = json.loads(row.result_data) if isinstance(row.result_data, str) else row.result_data
                    except (json.JSONDecodeError, TypeError):
                        result_data = row.result_data
                
                # ContextBlock ìƒì„±
                execution_result = None
                if result_data:
                    execution_result = {
                        'data': result_data,
                        'row_count': row.result_row_count or 0,
                        'generated_sql': row.generated_sql
                    }
                
                context_block = ContextBlock(
                    block_id=row.message_id,
                    user_id=user_id,
                    timestamp=row.timestamp,
                    block_type=BlockType.QUERY,
                    user_request=row.user_question or "",
                    assistant_response=row.assistant_answer or "",
                    execution_result=execution_result,
                    status="completed"
                )
                
                context_blocks.append(context_block)
            
            logger.info(f"ğŸ“š ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì™„ë£Œ: {len(context_blocks)}ê°œ ContextBlock (user_id: {user_id})")
            return {
                "success": True, 
                "context_blocks": context_blocks,
                "count": len(context_blocks)
            }
            
        except Exception as e:
            logger.error(f"í†µí•© ëŒ€í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e), "context_blocks": []}




