# Context Persistence Implementation Summary

## 개요
LLM과의 대화에서 이전 대화 기록을 함께 전송하여 맥락에 맞는 대화를 가능하게 하는 기능을 구현했습니다. 사용자 ID 기반의 맥락 유지 시스템을 통해 conversation_id가 변경되어도 연속적인 대화 경험을 제공합니다.

## 구현된 주요 기능

### 1. 통합 아키텍처 (Unified Architecture)
- **`_execute_with_context()` 메서드**: 모든 LLM 호출에서 컨텍스트를 처리하는 통합 메서드
- **Context Processor Pattern**: 카테고리별 컨텍스트 처리 로직 분리
- **코드 중복 제거**: 3개의 `_with_context()` 함수를 하나로 통합

### 2. 대화 컨텍스트 관리
- **2단계 컨텍스트 로딩**: conversation_id 기반 → user_id 기반 폴백
- **토큰 최적화**: 한국어 특성을 고려한 토큰 계산 (2.5 characters per token)
- **메시지 제한**: 최대 5개 메시지로 제한하여 성능 최적화

### 3. 분류 시스템 확장
- **기본 카테고리 (5개)**: query_request, metadata_request, data_analysis, guide_request, out_of_scope
- **컨텍스트 기반 카테고리 (4개)**: follow_up_query, refinement_request, comparison_analysis, clarification_request
- **총 9개 카테고리**로 확장하여 더 정확한 의도 파악

### 4. 프롬프트 템플릿 시스템
- **JSON 기반 템플릿**: 각 카테고리별 컨텍스트 지원 프롬프트
- **변수 치환**: `conversation_context`, `question`, `data_context` 등
- **폴백 메커니즘**: 컨텍스트가 없을 때 기본 프롬프트 사용

## 파일별 구현 내용

### `/backend/utils/bigquery/conversation_service.py`
```python
def get_conversation_context(self, conversation_id: str, user_id: str, max_messages: int = 5) -> Dict[str, Any]
def optimize_context_size(self, messages: List[Dict], max_tokens: int = 1000) -> List[Dict]
def get_user_recent_context(self, user_id: str, max_messages: int = 5, exclude_conversation_id: str = None) -> Dict[str, Any]
```
- conversation_id 기반 컨텍스트 조회
- 토큰 크기 최적화
- user_id 기반 최근 컨텍스트 조회 (폴백)
- message_id 포함하여 query_results 테이블 연동 준비

### `/backend/utils/llm_client.py`
```python
def _execute_with_context(self, category: str, input_data: Dict[str, Any], 
                         conversation_context: List[Dict] = None, 
                         context_processor: callable = None) -> dict
```
- 통합 컨텍스트 처리 메서드
- 카테고리별 context processor 지원
- 기존 메서드들을 통합 아키텍처로 리팩터링

### `/backend/routes/chat_routes.py`
- 2단계 컨텍스트 로딩 로직 구현
- 컨텍스트 기반 카테고리 처리 추가
- 디버깅 로그 강화
- **현재 상태**: 스키마 정리 계획이 적용되어 간소화됨

### 프롬프트 템플릿 파일들
- `/backend/utils/prompts/classification.json`: 9개 카테고리 분류 지원
- `/backend/utils/prompts/sql_generation.json`: SQL 생성용 컨텍스트 템플릿
- `/backend/utils/prompts/data_analysis.json`: 데이터 분석용 컨텍스트 템플릿

## 해결된 주요 문제

### 1. 코드 중복 제거
- **문제**: `classify_input_with_context()`, `generate_sql_with_context()`, `analyze_data_with_context()` 함수들의 중복
- **해결**: `_execute_with_context()` 통합 메서드로 중복 제거

### 2. Conversation ID 변경 문제
- **문제**: conversation_id가 변경되면 컨텍스트가 손실됨
- **해결**: user_id 기반 폴백 시스템 구현

### 3. 분류 정확도 문제
- **문제**: "결과 해설", "분석" 등이 follow_up_query로 잘못 분류됨
- **해결**: 분류 프롬프트에 구체적인 예시 추가, data_analysis 카테고리 강화

### 4. 템플릿 변수 불일치
- **문제**: `user_question` vs `question` 변수명 불일치
- **해결**: 모든 템플릿을 `question`으로 통일

### 5. Import 오류
- **문제**: `List` 타입 import 누락
- **해결**: `from typing import List` 추가

## 성능 최적화

### 1. 토큰 관리
- 한국어 특성 고려: 2.5 characters per token
- 최대 1000 토큰으로 컨텍스트 크기 제한
- 오래된 메시지부터 제거하는 최적화

### 2. 쿼리 최적화
- 최대 5개 메시지로 제한
- 시간순 정렬로 최신 메시지 우선
- 인덱스 활용을 위한 쿼리 구조

### 3. 메모리 효율성
- 필요한 필드만 선택적 조회
- 컨텍스트 크기 동적 조정

## 디버깅 및 모니터링

### 1. 로깅 시스템
- 컨텍스트 로드 상태 추적
- 메시지 구조 디버깅
- 분류 결과 모니터링
- 성능 메트릭 수집

### 2. 에러 처리
- 컨텍스트 로드 실패 시 graceful degradation
- 분류 실패 시 기본 카테고리로 폴백
- 상세한 에러 메시지와 로깅

## 현재 진행 중인 작업

### Query Results 테이블 통합
- **목표**: 실제 쿼리 결과 데이터를 분석 컨텍스트에 포함
- **현재 상태**: conversation_service에 message_id 추가 완료
- **다음 단계**: chat_routes에서 실제 query_results 데이터 조회 및 활용

## 기술적 특징

### 1. 확장 가능한 설계
- 새로운 카테고리 추가 용이
- 컨텍스트 프로세서 패턴으로 로직 분리
- JSON 기반 템플릿으로 프롬프트 관리

### 2. 호환성 유지
- 기존 API 인터페이스 유지
- 컨텍스트가 없을 때도 정상 동작
- 점진적 기능 활성화

### 3. 안정성
- 포괄적인 에러 처리
- 폴백 메커니즘
- 성능 저하 없는 확장

## 사용자 경험 개선

### 1. 자연스러운 대화
- 이전 대화 맥락을 기억하는 AI
- 연속적인 질문-답변 흐름
- 컨텍스트 기반 정확한 분류

### 2. 세션 연속성
- conversation_id 변경에도 컨텍스트 유지
- 사용자별 개인화된 대화 경험
- 브라우저 새로고침 후에도 연속성 보장

### 3. 향상된 분석
- 이전 쿼리 결과를 참고한 분석
- 트렌드 및 패턴 인식
- 비교 분석 지원

이 구현을 통해 단순한 질의응답에서 벗어나 지능적이고 맥락적인 대화가 가능한 시스템을 구축했습니다.