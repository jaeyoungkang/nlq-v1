"""
BigQuery AI Assistant - ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (ë¦¬íŒ©í† ë§ ë²„ì „)
LLM í´ë¼ì´ì–¸íŠ¸ í†µí•© ë° ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ 
"""

import os
import json
import logging
import time
import datetime
from typing import Dict, List, Optional
from dotenv import load_dotenv
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS

# í†µí•©ëœ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ì„í¬íŠ¸
from utils.llm_client import LLMClientFactory
from utils.bigquery_utils import BigQueryClient

# --- ì„¤ì • ë° ë¡œê¹… ---

# .env.local íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv('.env.local')

# ê°œì„ ëœ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# Flask ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app, 
     origins=["http://localhost:8080", "http://127.0.0.1:8080"],
     allow_headers=["Content-Type", "Cache-Control"],
     expose_headers=["Cache-Control"],
     supports_credentials=False)

# --- ê¸€ë¡œë²Œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---

# ê¸€ë¡œë²Œ í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
llm_client = None
bigquery_client = None

# í‘œì¤€í™”ëœ ì—ëŸ¬ ì‘ë‹µ í¬ë§·
class ErrorResponse:
    """í‘œì¤€í™”ëœ ì—ëŸ¬ ì‘ë‹µ í´ë˜ìŠ¤"""
    
    @staticmethod
    def create(error_message: str, error_type: str = "general", details: dict = None):
        """í‘œì¤€í™”ëœ ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            "success": False,
            "error": error_message,
            "error_type": error_type,
            "details": details or {},
            "timestamp": datetime.datetime.now().isoformat()
        }
    
    @staticmethod
    def validation_error(message: str):
        """ì…ë ¥ ê²€ì¦ ì—ëŸ¬"""
        return ErrorResponse.create(message, "validation_error")
    
    @staticmethod
    def service_error(message: str, service: str):
        """ì„œë¹„ìŠ¤ë³„ ì—ëŸ¬"""
        return ErrorResponse.create(message, "service_error", {"service": service})
    
    @staticmethod
    def internal_error(message: str):
        """ë‚´ë¶€ ì„œë²„ ì—ëŸ¬"""
        return ErrorResponse.create(message, "internal_error")

def initialize_clients():
    """API í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì´ˆê¸°í™” (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    global llm_client, bigquery_client
    
    try:
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        llm_provider = os.getenv('LLM_PROVIDER', 'anthropic')
        api_key = os.getenv('ANTHROPIC_API_KEY')
        
        if api_key:
            llm_client = LLMClientFactory.create_client(llm_provider, {'api_key': api_key})
            logger.info(f"âœ… {llm_provider} LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        project_id = os.getenv('GOOGLE_CLOUD_PROJECT')
        location = os.getenv('BIGQUERY_LOCATION', 'asia-northeast3')
        
        if project_id:
            bigquery_client = BigQueryClient(project_id, location)
            logger.info(f"âœ… BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (í”„ë¡œì íŠ¸: {project_id}, ë¦¬ì „: {location})")
        else:
            logger.warning("âš ï¸ GOOGLE_CLOUD_PROJECTê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        raise

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    initialize_clients()
except Exception as e:
    logger.critical(f"ğŸš¨ ì•± ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€ - ëœë”© í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    return render_template('landing.html')

@app.route('/landing')
def landing_page():
    """ëœë”© í˜ì´ì§€"""
    return render_template('landing.html')

@app.route('/app')
def chat_app():
    """ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜"""
    return render_template('index.html')

@app.route('/api/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ (ê°œì„ ëœ ë²„ì „)"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.datetime.now().isoformat(),
        "version": "2.1.0-refactored",
        "services": {
            "llm": {
                "status": "available" if llm_client else "unavailable",
                "provider": os.getenv('LLM_PROVIDER', 'anthropic')
            },
            "bigquery": {
                "status": "available" if bigquery_client else "unavailable",
                "project": os.getenv('GOOGLE_CLOUD_PROJECT', 'N/A'),
                "location": os.getenv('BIGQUERY_LOCATION', 'asia-northeast3')
            }
        },
        "environment": {
            "flask_env": os.getenv('FLASK_ENV', 'production'),
            "debug_mode": app.debug
        }
    }
    
    # ì „ì²´ ì„œë¹„ìŠ¤ ìƒíƒœ íŒë‹¨
    all_services_available = all(
        service["status"] == "available" 
        for service in health_status["services"].values()
    )
    
    if not all_services_available:
        health_status["status"] = "degraded"
        return jsonify(health_status), 503
    
    return jsonify(health_status)

@app.route('/api/chat', methods=['POST'])
def process_chat():
    """
    í†µí•© ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)
    ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ìˆ˜í–‰
    """
    start_time = time.time()
    request_id = f"req_{int(time.time())}_{id(request)}"
    
    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        if not request.json:
            return jsonify(ErrorResponse.validation_error("JSON ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")), 400
        
        message = request.json.get('message', '').strip()
        context = request.json.get('context', {})
        
        if not message:
            return jsonify(ErrorResponse.validation_error("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")), 400
        
        if len(message) > 1000:
            return jsonify(ErrorResponse.validation_error("ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 1000ì)")), 400
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
        if not llm_client:
            return jsonify(ErrorResponse.service_error(
                "LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "llm"
            )), 500
        
        logger.info(f"ğŸ¯ [{request_id}] ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘: {message[:50]}...")
        
        # 1ë‹¨ê³„: ì‚¬ìš©ì ì…ë ¥ ë¶„ë¥˜ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)
        classification_result = llm_client.classify_input(message)
        
        if not classification_result["success"]:
            logger.error(f"âŒ [{request_id}] ì…ë ¥ ë¶„ë¥˜ ì‹¤íŒ¨: {classification_result.get('error')}")
            return jsonify(ErrorResponse.service_error(
                f"ì…ë ¥ ë¶„ë¥˜ ì‹¤íŒ¨: {classification_result['error']}", "llm"
            )), 500
        
        classification = classification_result["classification"]
        category = classification["category"]
        
        logger.info(f"ğŸ“‹ [{request_id}] ì…ë ¥ ë¶„ë¥˜: {category} (ì‹ ë¢°ë„: {classification['confidence']})")
        
        # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬ (ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ )
        try:
            if category == "query_request":
                result = handle_query_request(message, context, request_id)
            elif category == "metadata_request":
                result = handle_metadata_request(message, context, request_id)
            elif category == "data_analysis":
                result = handle_data_analysis(message, context, request_id)
            elif category == "guide_request":
                result = handle_guide_request(message, context, request_id)
            else:  # out_of_scope
                result = handle_out_of_scope(message, context, request_id)
                
        except Exception as e:
            logger.error(f"âŒ [{request_id}] ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return jsonify(ErrorResponse.service_error(
                f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", category
            )), 500
        
        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        execution_time_ms = round((time.time() - start_time) * 1000, 2)
        
        # ì„±ê³µ ì‘ë‹µ (í‘œì¤€í™”ëœ í¬ë§·)
        response_data = {
            "success": True,
            "request_id": request_id,
            "message": message,
            "category": category,
            "classification": classification,
            "result": result,
            "performance": {
                "execution_time_ms": execution_time_ms,
                "timestamp": datetime.datetime.now().isoformat()
            }
        }
        
        logger.info(f"âœ… [{request_id}] ì²˜ë¦¬ ì™„ë£Œ ({execution_time_ms}ms)")
        return jsonify(response_data)
        
    except Exception as e:
        execution_time_ms = round((time.time() - start_time) * 1000, 2)
        logger.error(f"âŒ [{getattr(locals(), 'request_id', 'unknown')}] ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(e)}")
        
        error_response = ErrorResponse.internal_error(f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
        error_response["performance"] = {
            "execution_time_ms": execution_time_ms,
            "timestamp": datetime.datetime.now().isoformat()
        }
        
        return jsonify(error_response), 500

def handle_query_request(message: str, context: dict, request_id: str) -> dict:
    """ì¿¼ë¦¬ ìƒì„± ìš”ì²­ ì²˜ë¦¬ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    try:
        if not bigquery_client:
            raise ValueError("BigQuery í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # SQL ìƒì„±
        logger.info(f"ğŸ”§ [{request_id}] SQL ìƒì„± ì‹œì‘")
        sql_result = llm_client.generate_sql(message, bigquery_client.project_id)
        
        if not sql_result["success"]:
            raise ValueError(f"SQL ìƒì„± ì‹¤íŒ¨: {sql_result['error']}")
        
        generated_sql = sql_result["sql"]
        logger.info(f"ğŸ“ [{request_id}] ìƒì„±ëœ SQL: {generated_sql[:100]}...")
        
        # BigQuery ì‹¤í–‰
        logger.info(f"âš¡ [{request_id}] BigQuery ì¿¼ë¦¬ ì‹¤í–‰ ì‹œì‘")
        query_result = bigquery_client.execute_query(generated_sql)
        
        if not query_result["success"]:
            # BigQuery ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
            error_type = query_result.get("error_type", "execution_error")
            raise ValueError(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨ ({error_type}): {query_result['error']}")
        
        logger.info(f"âœ… [{request_id}] ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ: {query_result['row_count']}í–‰")
        
        return {
            "type": "query_result",
            "generated_sql": generated_sql,
            "data": query_result["data"],
            "row_count": query_result["row_count"],
            "stats": query_result.get("stats", {})
        }
        
    except Exception as e:
        logger.error(f"âŒ [{request_id}] ì¿¼ë¦¬ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "type": "error",
            "error": str(e),
            "generated_sql": locals().get("generated_sql", None)
        }

def handle_metadata_request(message: str, context: dict, request_id: str) -> dict:
    """ë©”íƒ€ë°ì´í„° ìš”ì²­ ì²˜ë¦¬ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    try:
        if not bigquery_client:
            raise ValueError("BigQuery í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        logger.info(f"ğŸ“‹ [{request_id}] ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹œì‘")
        metadata_result = bigquery_client.get_default_table_metadata()
        
        if not metadata_result["success"]:
            raise ValueError(f"ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {metadata_result['error']}")
        
        # LLMìœ¼ë¡œ ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ ìƒì„±
        logger.info(f"ğŸ¤– [{request_id}] ë©”íƒ€ë°ì´í„° ì‘ë‹µ ìƒì„± ì‹œì‘")
        response_result = llm_client.generate_metadata_response(message, metadata_result)
        
        if not response_result["success"]:
            raise ValueError(f"ë©”íƒ€ë°ì´í„° ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {response_result['error']}")
        
        logger.info(f"âœ… [{request_id}] ë©”íƒ€ë°ì´í„° ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        
        return {
            "type": "metadata",
            "response": response_result["response"],
            "raw_metadata": metadata_result
        }
        
    except Exception as e:
        logger.error(f"âŒ [{request_id}] ë©”íƒ€ë°ì´í„° ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "type": "error",
            "error": str(e)
        }

def handle_data_analysis(message: str, context: dict, request_id: str) -> dict:
    """ë°ì´í„° ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    try:
        previous_data = context.get("previous_data", [])
        previous_sql = context.get("previous_sql", "")
        
        logger.info(f"ğŸ” [{request_id}] ë°ì´í„° ë¶„ì„ ì‹œì‘ (ë°ì´í„°: {len(previous_data)}í–‰)")
        
        analysis_result = llm_client.analyze_data(message, previous_data, previous_sql)
        
        if not analysis_result["success"]:
            raise ValueError(f"ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {analysis_result['error']}")
        
        logger.info(f"âœ… [{request_id}] ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
        
        return {
            "type": "analysis",
            "analysis": analysis_result["analysis"]
        }
        
    except Exception as e:
        logger.error(f"âŒ [{request_id}] ë°ì´í„° ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "type": "error",
            "error": str(e)
        }

def handle_guide_request(message: str, context: dict, request_id: str) -> dict:
    """ê°€ì´ë“œ ìš”ì²­ ì²˜ë¦¬ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    try:
        context_info = f"ì‚¬ìš©ìê°€ BigQuery Assistantë¥¼ ì‚¬ìš© ì¤‘"
        if context.get("previous_queries"):
            context_info += f", ì´ì „ì— {len(context['previous_queries'])}ê°œì˜ ì¿¼ë¦¬ ì‹¤í–‰"
        
        logger.info(f"ğŸ’¡ [{request_id}] ê°€ì´ë“œ ì‘ë‹µ ìƒì„± ì‹œì‘")
        
        guide_result = llm_client.generate_guide(message, context_info)
        
        if not guide_result["success"]:
            raise ValueError(f"ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {guide_result['error']}")
        
        logger.info(f"âœ… [{request_id}] ê°€ì´ë“œ ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        
        return {
            "type": "guide",
            "guide": guide_result["guide"]
        }
        
    except Exception as e:
        logger.error(f"âŒ [{request_id}] ê°€ì´ë“œ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "type": "error",
            "error": str(e)
        }

def handle_out_of_scope(message: str, context: dict, request_id: str) -> dict:
    """ê¸°ëŠ¥ ë²”ìœ„ ì™¸ ìš”ì²­ ì²˜ë¦¬ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    try:
        logger.info(f"ğŸš« [{request_id}] ë²”ìœ„ ì™¸ ìš”ì²­ ì²˜ë¦¬")
        
        scope_result = llm_client.generate_out_of_scope(message)
        
        if not scope_result["success"]:
            raise ValueError(f"ë²”ìœ„ ì™¸ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {scope_result['error']}")
        
        logger.info(f"âœ… [{request_id}] ë²”ìœ„ ì™¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ")
        
        return {
            "type": "out_of_scope",
            "response": scope_result["response"]
        }
        
    except Exception as e:
        logger.error(f"âŒ [{request_id}] ë²”ìœ„ ì™¸ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return {
            "type": "error",
            "error": str(e)
        }

@app.route('/api/validate-sql', methods=['POST'])
def validate_sql():
    """SQL ì¿¼ë¦¬ ë¬¸ë²• ê²€ì¦ (ê°œì„ ëœ ì—ëŸ¬ í•¸ë“¤ë§)"""
    request_id = f"val_{int(time.time())}"
    
    try:
        if not request.json or 'sql' not in request.json:
            return jsonify(ErrorResponse.validation_error("SQL ì¿¼ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")), 400
        
        sql_query = request.json['sql'].strip()
        
        if len(sql_query) > 10000:
            return jsonify(ErrorResponse.validation_error("SQL ì¿¼ë¦¬ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 10,000ì)")), 400
        
        if not bigquery_client:
            return jsonify(ErrorResponse.service_error(
                "BigQuery í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", "bigquery"
            )), 500
        
        logger.info(f"ğŸ” [{request_id}] SQL ê²€ì¦ ì‹œì‘: {sql_query[:50]}...")
        
        # ë“œë¼ì´ ëŸ°ìœ¼ë¡œ SQL ê²€ì¦
        validation_result = bigquery_client.validate_query(sql_query)
        
        if validation_result["success"]:
            logger.info(f"âœ… [{request_id}] SQL ê²€ì¦ ì™„ë£Œ")
        else:
            logger.warning(f"âš ï¸ [{request_id}] SQL ê²€ì¦ ì‹¤íŒ¨: {validation_result.get('error')}")
        
        validation_result["request_id"] = request_id
        validation_result["timestamp"] = datetime.datetime.now().isoformat()
        
        return jsonify(validation_result)
        
    except Exception as e:
        logger.error(f"âŒ [{request_id}] SQL ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        error_response = ErrorResponse.service_error(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}", "bigquery")
        error_response["request_id"] = request_id
        return jsonify(error_response), 500

@app.errorhandler(404)
def not_found(error):
    """404 ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ (ê°œì„ ëœ ë²„ì „)"""
    return jsonify(ErrorResponse.create(
        "ìš”ì²­í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
        "not_found",
        {
            "available_endpoints": [
                "GET /",
                "GET /landing", 
                "GET /app",
                "GET /api/health", 
                "POST /api/chat",
                "POST /api/validate-sql"
            ],
            "method": request.method,
            "path": request.path
        }
    )), 404

@app.errorhandler(500)
def internal_error(error):
    """500 ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ (ê°œì„ ëœ ë²„ì „)"""
    logger.error(f"âŒ ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {error}")
    return jsonify(ErrorResponse.internal_error(
        "ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    )), 500

@app.errorhandler(413)
def request_too_large(error):
    """413 ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ (ìš”ì²­ í¬ê¸° ì´ˆê³¼)"""
    return jsonify(ErrorResponse.validation_error(
        "ìš”ì²­ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. íŒŒì¼ í¬ê¸°ë¥¼ ì¤„ì—¬ì£¼ì„¸ìš”."
    )), 413

@app.errorhandler(429)
def rate_limit_exceeded(error):
    """429 ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ (ìš”ì²­ ì œí•œ ì´ˆê³¼)"""
    return jsonify(ErrorResponse.create(
        "ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        "rate_limit_exceeded"
    )), 429

if __name__ == '__main__':
    logger.info("ğŸš€ === BigQuery AI Assistant ì„œë²„ ì‹œì‘ (ë¦¬íŒ©í† ë§ ë²„ì „) ===")
    logger.info(f"LLM: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if llm_client else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")
    logger.info(f"BigQuery: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if bigquery_client else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")
    
    # Cloud Runì—ì„œëŠ” PORT í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
    port = int(os.getenv('PORT', 8080))
    debug_mode = os.getenv('FLASK_ENV') == 'development'
    
    logger.info(f"ğŸŒ ì„œë²„ ì‹œì‘: http://0.0.0.0:{port}")
    logger.info(f"ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: {debug_mode}")
    
    app.run(debug=debug_mode, host='0.0.0.0', port=port)