# backend/utils/bigquery/conversation_service.py
"""
BigQuery ëŒ€í™” ì„œë¹„ìŠ¤
ëŒ€í™” ì €ì¥/ì¡°íšŒ/ì‚­ì œ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©
"""

import os
import json
import logging
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, List
from google.cloud import bigquery
from google.cloud.exceptions import NotFound

logger = logging.getLogger(__name__)

class ConversationService:
    """BigQuery ëŒ€í™” ê´€ë¦¬ ì„œë¹„ìŠ¤ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©"""
    
    def __init__(self, project_id: str, location: str = "asia-northeast3"):
        """
        ConversationService ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            location: BigQuery ë¦¬ì „
        """
        self.project_id = project_id
        self.location = location
        try:
            self.client = bigquery.Client(project=project_id, location=location)
            logger.info(f"BigQuery ConversationService ì´ˆê¸°í™” ì™„ë£Œ: {project_id}")
        except Exception as e:
            logger.error(f"BigQuery ConversationService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    
    def save_conversation(self, conversation_data: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™” ë‚´ìš©ì„ BigQueryì— ì €ì¥"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            table_id = f"{self.project_id}.{dataset_name}.conversations"
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['message_id', 'message_type', 'user_id']
            if any(field not in conversation_data for field in required_fields):
                raise ValueError(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {required_fields}")

            # ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë°ì´í„° ì •ë¦¬
            clean_data = self._clean_conversation_data(conversation_data)
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": False, "error": table_check_result['error']}

            # ë°ì´í„° ì‚½ì… - TableReference ì‚¬ìš©
            table_ref = self.client.dataset(dataset_name).table('conversations')
            errors = self.client.insert_rows_json(table_ref, [clean_data])
            
            if errors:
                logger.error(f"ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: {errors}")
                return {"success": False, "error": f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {errors[0]}"}
            
            logger.info(f"ğŸ’¾ ëŒ€í™” ì €ì¥ ì™„ë£Œ: {clean_data['message_id']} - {clean_data['message_type']}")
            return {"success": True, "message": "ëŒ€í™”ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e)}

    def save_complete_interaction(self, 
                                user_id: str, 
                                user_question: str,
                                assistant_answer: str, 
                                generated_sql: str = None,
                                query_result: dict = None,
                                context_message_ids: List[str] = None) -> Dict[str, Any]:
        """ì§ˆë¬¸-ë‹µë³€-ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì €ì¥ (í†µí•© êµ¬ì¡°)"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": False, "error": table_check_result['error']}
            
            message_id = str(uuid.uuid4())
            current_time = datetime.now(timezone.utc)
            
            # í†µí•©ëœ ë°ì´í„° êµ¬ì¡°
            interaction_data = {
                'message_id': message_id,
                'user_id': user_id,
                'message_type': 'complete',  # ì§ˆë¬¸+ë‹µë³€ ì™„ì„±í˜•
                'message': f"Q: {user_question}\nA: {assistant_answer}",
                'timestamp': current_time.isoformat(),
                'generated_sql': generated_sql,
                'query_id': str(uuid.uuid4()) if query_result else None,
                'context_message_ids': context_message_ids or []
            }
            
            # ì¿¼ë¦¬ ê²°ê³¼ ì§ì ‘ í¬í•¨
            if query_result:
                interaction_data.update({
                    'result_data': query_result.get('data', []),
                    'result_row_count': query_result.get('row_count', 0),
                    'result_status': 'success' if query_result.get('success') else 'error',
                    'error_message': query_result.get('error')
                })
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            table_ref = self.client.dataset(dataset_name).table('conversations')
            errors = self.client.insert_rows_json(table_ref, [interaction_data])
            
            if errors:
                logger.error(f"ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì‹¤íŒ¨: {errors}")
                return {"success": False, "error": f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {errors[0]}"}
            
            logger.info(f"ğŸ’¾ ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì™„ë£Œ: {message_id}")
            return {"success": True, "message_id": message_id, "message": "ìƒí˜¸ì‘ìš©ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
            
        except Exception as e:
            logger.error(f"ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e)}

    def save_query_result(self, query_id: str, result_data: Dict[str, Any]) -> Dict[str, Any]:
        """DEPRECATED: í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (Phase 1 ì™„ë£Œ í›„ ì œê±° ì˜ˆì •)"""
        logger.warning("save_query_resultëŠ” deprecatedì…ë‹ˆë‹¤. save_complete_interactionì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return {"success": True, "query_id": query_id, "message": "deprecated method called"}

            
    def get_latest_conversation(self, user_id: str) -> Dict[str, Any]:
        """DEPRECATED: get_conversation_with_contextë¥¼ ì‚¬ìš©í•˜ì„¸ìš”"""
        logger.warning("get_latest_conversationëŠ” deprecatedì…ë‹ˆë‹¤. get_conversation_with_contextë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        return self.get_conversation_with_context(user_id, 50)

    def get_conversation_context(self, user_id: str, max_messages: int = 10) -> Dict[str, Any]:
        """LLM ì»¨í…ìŠ¤íŠ¸ìš© ëŒ€í™” ê¸°ë¡ ì¡°íšŒ - í†µí•©ëœ êµ¬ì¡° ì‚¬ìš©"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            table_id = f"{self.project_id}.{dataset_name}.conversations"
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": True, "context": [], "context_length": 0}
            
            # ìµœê·¼ ë©”ì‹œì§€ë“¤ì„ ì‹œê°„ìˆœìœ¼ë¡œ ì¡°íšŒ (ìµœëŒ€ max_messagesê°œ)
            query = f"""
            SELECT 
                message_id, message, timestamp,
                generated_sql, result_data, result_row_count
            FROM `{table_id}`
            WHERE user_id = @user_id
              AND message_type = 'complete'  -- ì™„ì„±í˜• ë©”ì‹œì§€ë§Œ ì¡°íšŒ
            ORDER BY timestamp DESC
            LIMIT @max_messages
            """
            
            job_config = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ScalarQueryParameter("user_id", "STRING", user_id),
                bigquery.ScalarQueryParameter("max_messages", "INT64", max_messages)
            ])
            
            rows = list(self.client.query(query, job_config=job_config).result())
            
            # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
            rows.reverse()
            
            context_messages = []
            for row in rows:
                # ì§ˆë¬¸ê³¼ ë‹µë³€ ë¶„ë¦¬
                message_parts = row.message.split('\\nA: ', 1) if row.message else ['', '']
                user_question = message_parts[0].replace('Q: ', '') if len(message_parts) > 0 else ''
                assistant_answer = message_parts[1] if len(message_parts) > 1 else ''
                
                # ì‚¬ìš©ì ë©”ì‹œì§€
                if user_question:
                    context_messages.append({
                        "role": "user",
                        "content": user_question,
                        "timestamp": row.timestamp.isoformat() if row.timestamp else None
                    })
                
                # AI ì‘ë‹µ ë©”ì‹œì§€
                if assistant_answer:
                    message_data = {
                        "role": "assistant",
                        "content": assistant_answer,
                        "timestamp": row.timestamp.isoformat() if row.timestamp else None,
                        "metadata": {
                            "generated_sql": row.generated_sql
                        }
                    }
                    
                    # ì¿¼ë¦¬ ê²°ê³¼ ì§ì ‘ í¬í•¨ (í†µí•© êµ¬ì¡°)
                    if row.result_data:
                        message_data['query_result_data'] = row.result_data
                        message_data['query_row_count'] = row.result_row_count
                        logger.info(f"ğŸ“Š ì»¨í…ìŠ¤íŠ¸ì— ì¿¼ë¦¬ ê²°ê³¼ í¬í•¨: {row.result_row_count}í–‰")
                    
                    context_messages.append(message_data)
            
            logger.info(f"ğŸ“š ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì™„ë£Œ: {len(context_messages)}ê°œ ë©”ì‹œì§€ (user_id: {user_id})")
            
            return {
                "success": True,
                "context": context_messages,
                "context_length": len(context_messages)
            }
            
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e), "context": [], "context_length": 0}

    def _get_query_results_by_ids(self, query_ids: List[str], dataset_name: str) -> Dict[str, Any]:
        """DEPRECATED: í†µí•© êµ¬ì¡°ì—ì„œëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ"""
        logger.warning("_get_query_results_by_idsëŠ” deprecatedì…ë‹ˆë‹¤. í†µí•© êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        return {}

    def get_conversation_with_context(self, user_id: str, limit: int = 10) -> Dict[str, Any]:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ëª¨ë“  ëŒ€í™” ê¸°ë¡ ì¡°íšŒ - JOIN ì—†ìŒ"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            table_id = f"{self.project_id}.{dataset_name}.conversations"
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": True, "conversations": [], "count": 0}
            
            query = f"""
            SELECT 
                message_id,
                message,
                generated_sql,
                result_data,
                result_row_count,
                result_status,
                timestamp,
                context_message_ids
            FROM `{table_id}`
            WHERE user_id = @user_id
            ORDER BY timestamp DESC
            LIMIT @limit
            """
            
            job_config = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ScalarQueryParameter('user_id', 'STRING', user_id),
                bigquery.ScalarQueryParameter('limit', 'INT64', limit)
            ])
            
            rows = list(self.client.query(query, job_config=job_config).result())
            
            conversations = []
            for row in rows:
                conv_data = {
                    "message_id": row.message_id,
                    "message": row.message,
                    "generated_sql": row.generated_sql,
                    "result_row_count": row.result_row_count,
                    "result_status": row.result_status,
                    "timestamp": row.timestamp.isoformat() if row.timestamp else None,
                    "context_message_ids": list(row.context_message_ids) if row.context_message_ids else []
                }
                
                # result_dataê°€ ìˆìœ¼ë©´ í¬í•¨
                if row.result_data:
                    conv_data["result_data"] = row.result_data
                    
                conversations.append(conv_data)
            
            logger.info(f"ğŸ“š ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì™„ë£Œ: {len(conversations)}ê°œ (user_id: {user_id})")
            return {"success": True, "conversations": conversations, "count": len(conversations)}
            
        except Exception as e:
            logger.error(f"í†µí•© ëŒ€í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e), "conversations": []}

    def _clean_conversation_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì €ì¥ì„ ìœ„í•´ ëŒ€í™” ë°ì´í„° ì •ë¦¬"""
        cleaned_data = {
            'message_id': data.get('message_id'),
            'user_id': data.get('user_id'),
            'message_type': data.get('message_type'),
            'message': data.get('message'),
            'timestamp': data.get('timestamp', datetime.now(timezone.utc).isoformat()),
            'generated_sql': data.get('generated_sql'),
            'query_id': data.get('query_id')
        }
        
        # í†µí•© êµ¬ì¡° ì»¬ëŸ¼ë“¤ ì¶”ê°€
        if 'result_data' in data:
            cleaned_data['result_data'] = data['result_data']
        if 'result_row_count' in data:
            cleaned_data['result_row_count'] = data['result_row_count']
        if 'result_status' in data:
            cleaned_data['result_status'] = data['result_status']
        if 'error_message' in data:
            cleaned_data['error_message'] = data['error_message']
        if 'context_message_ids' in data:
            cleaned_data['context_message_ids'] = data['context_message_ids']
            
        return cleaned_data

    def _ensure_table_exists(self, dataset_name: str, table_name: str, create_method: callable) -> Dict[str, Any]:
        """í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„± í—¬í¼"""
        table_ref = self.client.dataset(dataset_name).table(table_name)
        try:
            self.client.get_table(table_ref)
            return {"success": True, "action": "exists"}
        except NotFound:
            logger.info(f"í…Œì´ë¸” {table_name} ì—†ìŒ. ìƒì„± ì‹œë„.")
            result = create_method(dataset_name)
            # ë™ì‹œ ìƒì„±ìœ¼ë¡œ ì¸í•œ Already Exists ì—ëŸ¬ëŠ” ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
            if not result['success'] and 'Already Exists' in result.get('error', ''):
                logger.info(f"í…Œì´ë¸” {table_name} ì´ë¯¸ ì¡´ì¬í•¨ (ë™ì‹œ ìƒì„±ë¨)")
                return {"success": True, "action": "exists"}
            return result

    def _create_conversations_table(self, dataset_name: str) -> Dict[str, Any]:
        """í†µí•© êµ¬ì¡°ì˜ conversations í…Œì´ë¸” ìƒì„±"""
        table_id = f"{self.project_id}.{dataset_name}.conversations"
        try:
            schema = [
                # ê¸°ë³¸ í•„ë“œ
                bigquery.SchemaField("message_id", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("user_id", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("message_type", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("message", "STRING"),
                bigquery.SchemaField("timestamp", "TIMESTAMP", mode="REQUIRED"),
                bigquery.SchemaField("generated_sql", "STRING"),
                bigquery.SchemaField("query_id", "STRING"),
                
                # í†µí•© êµ¬ì¡° - ê²°ê³¼ ë°ì´í„° ì»¬ëŸ¼ë“¤
                bigquery.SchemaField("result_data", "JSON"),
                bigquery.SchemaField("result_row_count", "INT64"),
                bigquery.SchemaField("result_status", "STRING"),
                bigquery.SchemaField("error_message", "STRING"),
                bigquery.SchemaField("context_message_ids", "STRING", mode="REPEATED")
            ]
            table = bigquery.Table(table_id, schema=schema)
            table.time_partitioning = bigquery.TimePartitioning(type_=bigquery.TimePartitioningType.DAY, field="timestamp")
            self.client.create_table(table)
            logger.info(f"í†µí•© êµ¬ì¡° í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_id}")
            return {"success": True, "action": "created"}
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨ {table_id}: {e}")
            return {"success": False, "error": str(e)}

    def _create_query_results_table(self, dataset_name: str) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆë¡œ query_results í…Œì´ë¸” ìƒì„±"""
        table_id = f"{self.project_id}.{dataset_name}.query_results"
        try:
            schema = [
                bigquery.SchemaField("query_id", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("result_payload", "STRING"), # JSON as STRING
                bigquery.SchemaField("creation_time", "TIMESTAMP", mode="REQUIRED"),
            ]
            table = bigquery.Table(table_id, schema=schema)
            table.time_partitioning = bigquery.TimePartitioning(type_=bigquery.TimePartitioningType.DAY, field="creation_time")
            self.client.create_table(table)
            logger.info(f"í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_id}")
            return {"success": True, "action": "created"}
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨ {table_id}: {e}")
            return {"success": False, "error": str(e)}

    def get_user_conversations(self, user_id: str, limit: int = 50, offset: int = 0) -> Dict[str, Any]:
        """ì‚¬ìš©ìì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ëª©ë¡ ì¡°íšŒ - ë‹¨ì¼ ì“°ë ˆë“œ ëª¨ë¸"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            conversations_table = f"{self.project_id}.{dataset_name}.conversations"
            
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": True, "conversations": [], "count": 0}
            
            query = f"""
            SELECT 
                MIN(timestamp) as start_time,
                MAX(timestamp) as last_time,
                COUNT(*) as message_count,
                ARRAY_AGG(
                    CASE WHEN message_type = 'user' THEN message ELSE NULL END IGNORE NULLS
                    ORDER BY timestamp 
                    LIMIT 1
                )[SAFE_OFFSET(0)] as first_message
            FROM `{conversations_table}`
            WHERE user_id = @user_id
            """
            job_config = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ScalarQueryParameter("user_id", "STRING", user_id)
            ])
            
            results = self.client.query(query, job_config=job_config).result()
            row = next(iter(results), None)
            
            conversations = []
            if row and row.message_count > 0:
                conversations = [{
                    "user_id": user_id,
                    "start_time": row.start_time.isoformat() if row.start_time else None,
                    "last_time": row.last_time.isoformat() if row.last_time else None,
                    "message_count": row.message_count,
                    "first_message": row.first_message or "ëŒ€í™” ì—†ìŒ"
                }]
            
            return {"success": True, "conversations": conversations, "count": len(conversations)}
        except Exception as e:
            logger.error(f"ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e), "conversations": []}