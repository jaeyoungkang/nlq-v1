# backend/routes/chat_routes.py
"""
ì±„íŒ… ë° ëŒ€í™” ê´€ë ¨ ë¼ìš°íŠ¸ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©
"""

import os
import time
import json
import logging
import datetime
import uuid
from flask import Blueprint, request, jsonify, g, Response
from utils.auth_utils import require_auth
from utils.error_utils import ErrorResponse
from features.query_processing.services import QueryProcessingService
from features.query_processing.models import QueryRequest, QueryResult
from features.input_classification.services import InputClassificationService
from features.data_analysis.services import AnalysisService
from features.data_analysis.models import AnalysisRequest
from models import ContextBlock, BlockType

logger = logging.getLogger(__name__)

chat_bp = Blueprint('chat', __name__, url_prefix='/api')

def create_sse_event(event_type: str, data: dict) -> str:
    """SSE ì´ë²¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ìƒì„±"""
    return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"

@chat_bp.route('/chat-stream', methods=['POST'])
@require_auth
def process_chat_stream():
    """SSE ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (ì¸ì¦ëœ ì‚¬ìš©ì ì „ìš©)"""
    if not request.json:
        return jsonify(ErrorResponse.validation_error("JSON data is required")), 400
    
    message = request.json.get('message', '').strip()
    
    if not message:
        return jsonify(ErrorResponse.validation_error("Message cannot be empty")), 400

    def generate_stream():
        start_time = time.time()
        request_id = f"req_{int(time.time())}_{uuid.uuid4().hex[:6]}"
        
        try:
            from flask import current_app
            llm_client = getattr(current_app, 'llm_client', None)
            bigquery_client = getattr(current_app, 'bigquery_client', None)
            
            if not llm_client or not bigquery_client:
                yield create_sse_event('error', {'error': 'Service client not initialized', 'error_type': 'service_error'})
                return
            
            logger.info(f"ğŸ¯ [{request_id}] Processing streaming chat: {message[:50]}...")
            
            user_info = {'user_id': g.current_user['user_id'], 'email': g.current_user['email']}
            
            # ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ë¡œì§
            context_blocks = []
            try:
                context_result = bigquery_client.get_conversation_with_context(user_info['user_id'], limit=5)
                if context_result['success'] and 'context_blocks' in context_result:
                    context_blocks = list(reversed(context_result['context_blocks']))
                    logger.info(f"ğŸ“š [{request_id}] ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ: {len(context_blocks)}ê°œ ë¸”ë¡")
            except Exception as e:
                logger.error(f"âŒ [{request_id}] ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                context_blocks = []

            # 1. ì…ë ¥ ë¶„ë¥˜ (InputClassificationService ì‚¬ìš©)
            yield create_sse_event('progress', {'stage': 'classification', 'message': 'ğŸ” ì…ë ¥ ë¶„ë¥˜ ì¤‘...'})
            classification_service = InputClassificationService(llm_client)
            
            # ContextBlockì„ ì§ì ‘ ë¶„ë¥˜ ì„œë¹„ìŠ¤ì— ì „ë‹¬
            category = classification_service.classify(message, context_blocks)
            logger.info(f"ğŸ·ï¸ [{request_id}] Classified as: {category}")
            
            generated_sql = None
            
            # 2. ë¶„ë¥˜ì— ë”°ë¥¸ ì²˜ë¦¬ â†’ Query Processing Serviceë¡œ êµì²´ (ContextBlock ì‚¬ìš©)
            query_service = QueryProcessingService(llm_client, bigquery_client)
            
            # í˜„ì¬ ìš”ì²­ìš© ContextBlock ìƒì„±
            from datetime import datetime, timezone
            
            current_context_block = ContextBlock(
                block_id=str(uuid.uuid4()),
                user_id=user_info['user_id'],
                timestamp=datetime.now(timezone.utc),
                block_type=BlockType.QUERY,  # ê¸°ë³¸ê°’, ë‚˜ì¤‘ì— ë¶„ë¥˜ì— ë”°ë¼ ë³€ê²½ë¨
                user_request=message,  # ë‹¨ìˆœ ë¬¸ìì—´
                assistant_response="",  # ë¹ˆ ë¬¸ìì—´
                status="pending"
            )
            
            request_obj = QueryRequest(
                user_id=user_info['user_id'],
                query=message,
                context_block=current_context_block
            )
            
            # ë¶„ë¥˜ì— ë”°ë¥¸ ì§„í–‰ ìƒíƒœ í‘œì‹œ ë° ì²˜ë¦¬
            if category == "query_request":
                yield create_sse_event('progress', {'stage': 'sql_generation', 'message': 'ğŸ“ SQL ìƒì„± ì¤‘...'})
                yield create_sse_event('progress', {'stage': 'query_execution', 'message': 'âš¡ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...'})
                
                # SQL ì¿¼ë¦¬ ì²˜ë¦¬ (ì´ì „ context_blocks ì „ë‹¬)
                query_result = query_service.process_sql_query(request_obj, context_blocks)
                
            elif category == "data_analysis":
                yield create_sse_event('progress', {'stage': 'analysis', 'message': 'ğŸ“Š ë°ì´í„° ë¶„ì„ ì¤‘...'})
                
                # AnalysisServiceë¡œ ë°ì´í„° ë¶„ì„ ì²˜ë¦¬
                analysis_service = AnalysisService(llm_client, bigquery_client)
                analysis_request = AnalysisRequest(
                    user_id=user_info['user_id'],
                    query=message,
                    context_block=current_context_block,
                    context_blocks=context_blocks
                )
                
                analysis_result = analysis_service.process_analysis(analysis_request)
                
                # QueryResultë¡œ ë³€í™˜ (chat_routes.pyì˜ ê¸°ì¡´ ì‘ë‹µ í˜•ì‹ ìœ ì§€)
                query_result = QueryResult(
                    success=analysis_result.success,
                    result_type="analysis_result",
                    context_block=analysis_result.context_block,
                    content=analysis_result.analysis_content,
                    error=analysis_result.error
                )
                
            else:
                yield create_sse_event('progress', {'stage': 'response_generation', 'message': 'ğŸ’¬ ì‘ë‹µ ìƒì„± ì¤‘...'})
                
                # TODO: í–¥í›„ ResponseService êµ¬í˜„ ì‹œ ì‚¬ìš©
                # response_service = ResponseService(llm_client)
                # query_result = response_service.process_response(request_obj)
                
                # ì„ì‹œ: ë²”ìœ„ ì™¸ ì‘ë‹µ
                content = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì€ í˜„ì¬ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²”ìœ„ì…ë‹ˆë‹¤."
                current_context_block.assistant_response = content
                current_context_block.status = "completed"
                
                query_result = QueryResult(
                    success=True,
                    result_type="out_of_scope_result",
                    context_block=current_context_block,
                    content=content
                )
            
            if not query_result.success:
                raise ValueError(f"Query processing failed: {query_result.error}")
            
            execution_time_ms = round((time.time() - start_time) * 1000, 2)
            
            # AI ì‘ë‹µ ë‚´ìš©ì€ ContextBlockì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
            ai_response_content = query_result.context_block.assistant_response if query_result.context_block else ""
            
            # ìƒì„±ëœ SQL ì¶”ì¶œ (ì €ì¥ìš©)
            generated_sql = query_result.generated_sql if query_result.result_type == "query_result" else None
            
            # í†µí•© ì €ì¥: ì§ˆë¬¸-ë‹µë³€-ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì €ì¥
            # ContextBlock.execution_resultëŠ” ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            execution_result = None
            if (query_result.result_type == "query_result" and 
                query_result.context_block and 
                query_result.context_block.execution_result):
                execution_result = query_result.context_block.execution_result
            
            save_result = bigquery_client.save_complete_interaction(
                user_id=user_info['user_id'],
                user_question=message,
                assistant_answer=ai_response_content,
                generated_sql=generated_sql,
                query_result=execution_result,
                context_message_ids=[]  # í–¥í›„ í™•ì¥ ê°€ëŠ¥
            )
            
            if not save_result['success']:
                logger.warning(f"âš ï¸ [{request_id}] í†µí•© ìƒí˜¸ì‘ìš© ì €ì¥ ì‹¤íŒ¨: {save_result.get('error')}")

            # 4. ìµœì¢… ê²°ê³¼ ì „ì†¡
            yield create_sse_event('progress', {'stage': 'completed', 'message': 'âœ… ì™„ë£Œ!'})
            
            # í´ë¼ì´ì–¸íŠ¸ìš© ê²°ê³¼ êµ¬ì„±
            client_result = {
                "type": query_result.result_type,
                "block_id": query_result.context_block.block_id if query_result.context_block else None
            }
            
            if query_result.result_type == "query_result":
                client_result.update({
                    "generated_sql": query_result.generated_sql,
                    "data": query_result.data,
                    "row_count": query_result.row_count
                })
            else:
                client_result["content"] = query_result.content
            
            yield create_sse_event('result', {
                'success': True,
                'request_id': request_id,
                'result': client_result,
                'performance': {'execution_time_ms': execution_time_ms}
            })
            
            logger.info(f"âœ… [{request_id}] Streaming complete ({execution_time_ms}ms)")

        except Exception as e:
            logger.error(f"âŒ [{request_id}] Streaming error: {str(e)}")
            yield create_sse_event('error', {'error': f'Server error: {str(e)}', 'error_type': 'internal_error'})

    return Response(generate_stream(), mimetype='text/event-stream', headers={'Cache-Control': 'no-cache', 'Connection': 'keep-alive', 'X-Accel-Buffering': 'no'})


@chat_bp.route('/conversations/latest', methods=['GET'])
@require_auth
def get_latest_conversation():
    """ìµœê·¼ ëŒ€í™” ê¸°ë¡ì„ ContextBlock ê¸°ë°˜ìœ¼ë¡œ ì¡°íšŒí•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜"""
    try:
        user_id = g.current_user['user_id']
        from flask import current_app
        bigquery_client = getattr(current_app, 'bigquery_client', None)

        if not bigquery_client:
            return jsonify(ErrorResponse.service_error("BigQuery client not initialized", "bigquery")), 500

        # ContextBlock ê¸°ë°˜ ìµœì‹  ëŒ€í™” ì¡°íšŒ
        context_result = bigquery_client.get_conversation_with_context(user_id, 50)  # ìµœê·¼ 50ê°œ ì¡°íšŒ

        if not context_result.get('success'):
            logger.warning(f"ëŒ€í™” ì¡°íšŒ ì‹¤íŒ¨ (í…Œì´ë¸” ì—†ì„ ìˆ˜ ìˆìŒ): {context_result.get('error')}")
            return jsonify({"success": True, "conversation": {"messages": [], "message_count": 0}})
        
        # ëŒ€í™”ê°€ ì—†ëŠ” ê²½ìš°ì˜ ì‘ë‹µ
        if not context_result.get('context_blocks') or len(context_result['context_blocks']) == 0:
            return jsonify({"success": True, "conversation": {"messages": [], "message_count": 0}})
            
        # ContextBlockì„ í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_messages = []
        for context_block in context_result['context_blocks']:
            # ì‚¬ìš©ì ë©”ì‹œì§€
            if context_block.user_request:
                formatted_messages.append({
                    "message_id": f"{context_block.block_id}_user",
                    "message": context_block.user_request,
                    "message_type": "user",
                    "timestamp": context_block.timestamp.isoformat() if context_block.timestamp else None
                })
            
            # AI ì‘ë‹µ ë©”ì‹œì§€
            if context_block.assistant_response:
                assistant_msg = {
                    "message_id": f"{context_block.block_id}_assistant", 
                    "message": context_block.assistant_response,
                    "message_type": "assistant",
                    "timestamp": context_block.timestamp.isoformat() if context_block.timestamp else None,
                    "generated_sql": context_block.execution_result.get('generated_sql') if context_block.execution_result else None,
                    "result_data": context_block.execution_result.get('data') if context_block.execution_result else None,
                    "result_row_count": context_block.execution_result.get('row_count') if context_block.execution_result else None
                }
                formatted_messages.append(assistant_msg)
        
        return jsonify({
            "success": True,
            "conversation": {
                "messages": formatted_messages,
                "message_count": len(formatted_messages)
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ ì „ì²´ ëŒ€í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify(ErrorResponse.internal_error(f"ì „ì²´ ëŒ€í™” ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")), 500

