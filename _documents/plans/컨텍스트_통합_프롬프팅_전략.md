# 컨텍스트 통합 프롬프팅 전략

## 현재 구조 분석

### 현재 문제점
- 컨텍스트 유무에 따라 다른 프롬프트 템플릿 사용
  - `system_prompt` vs `system_prompt_with_context`
  - `user_prompt` vs `user_prompt_with_context`
- 코드 복잡성 증가 및 유지보수 어려움
- 템플릿 일관성 부족

### 현재 구현 방식
```python
# llm_client.py:118-120
has_context = bool(conversation_context and len(conversation_context) > 0)
system_template = 'system_prompt_with_context' if has_context else 'system_prompt'
user_template = 'user_prompt_with_context' if has_context else 'user_prompt'
```

## 통합 전략: 빈 컨텍스트 방식

### 핵심 아이디어
컨텍스트가 없을 때 빈 컨텍스트를 전달하여 항상 같은 템플릿을 사용하는 방식으로 통합

### 1. 템플릿 구조 통합

#### 현재 구조
```json
{
  "system_prompt": "기본 프롬프트...",
  "system_prompt_with_context": "컨텍스트 고려 프롬프트...",
  "user_prompt": "분류할 입력: $user_input", 
  "user_prompt_with_context": "이전 대화:\n$conversation_context\n\n현재 사용자 입력: $user_input..."
}
```

#### 통합 후 구조
```json
{
  "system_prompt": "컨텍스트를 고려한 통합 프롬프트...",
  "user_prompt": "이전 대화:\n$conversation_context\n\n현재 사용자 입력: $user_input..."
}
```

### 2. 빈 컨텍스트 처리 로직

#### 컨텍스트 정규화 함수
```python
def _normalize_context(self, conversation_context: List[Dict] = None) -> str:
    """
    컨텍스트를 정규화하여 항상 문자열 반환
    - 컨텍스트 있음: 포맷된 대화 내용
    - 컨텍스트 없음: 빈 컨텍스트 메시지
    """
    if not conversation_context or len(conversation_context) == 0:
        return "[이전 대화 없음]"
    
    return self._format_conversation_context(conversation_context)
```

#### 통합된 프롬프트 생성
```python
def _execute_unified_prompting(self, category: str, input_data: Dict[str, Any], 
                              conversation_context: List[Dict] = None) -> dict:
    """
    통합 프롬프팅 시스템 - 항상 같은 템플릿 사용
    """
    # 컨텍스트 정규화
    normalized_context = self._normalize_context(conversation_context)
    
    # 단일 템플릿 사용
    system_prompt = prompt_manager.get_prompt(
        category=category,
        template_name='system_prompt',  # 항상 같은 템플릿
        **input_data,
        conversation_context=normalized_context
    )
    
    user_prompt = prompt_manager.get_prompt(
        category=category,
        template_name='user_prompt',  # 항상 같은 템플릿
        **input_data,
        conversation_context=normalized_context
    )
```

### 3. 프롬프트 템플릿 수정

#### Classification 템플릿 통합
```json
{
  "system_prompt": {
    "content": "사용자 입력을 9개 카테고리로 분류하고 JSON으로 응답:\n\n**기본 카테고리:**\n1. **query_request** - BigQuery 데이터 조회 요청\n2. **metadata_request** - 테이블/스키마 정보 요청\n3. **data_analysis** - 조회된 데이터 분석 요청\n4. **guide_request** - 사용법/안내 요청\n5. **out_of_scope** - 기능 범위 외 요청\n\n**컨텍스트 기반 확장 카테고리:**\n6. **follow_up_query** - 이전 쿼리 결과에 대한 후속 질문\n7. **refinement_request** - 이전 쿼리 수정/개선 요청\n8. **comparison_analysis** - 이전 결과와의 비교 분석\n9. **clarification_request** - 이전 응답에 대한 명확화 요청\n\n**컨텍스트 처리 규칙:**\n- 이전 대화가 '[이전 대화 없음]'인 경우: 기본 카테고리(1-5)만 사용\n- 이전 대화가 있는 경우: 모든 카테고리(1-9) 고려\n\nJSON 형식으로만 응답: {\"category\": \"분류\", \"confidence\": 0.95, \"reasoning\": \"이유\"}"
  },
  "user_prompt": {
    "content": "이전 대화:\n$conversation_context\n\n현재 사용자 입력: $user_input\n\n위 정보를 종합하여 현재 입력을 분류해주세요.",
    "variables": ["conversation_context", "user_input"]
  }
}
```

#### SQL Generation 템플릿 통합
```json
{
  "system_prompt": {
    "content": "BigQuery SQL 전문가로서 자연어를 SQL로 변환해주세요.\n\n**프로젝트 정보:**\n- 프로젝트 ID: $project_id\n- 기본 테이블: $default_table\n$dataset_info\n\n**컨텍스트 처리 규칙:**\n- 이전 대화가 '[이전 대화 없음]'인 경우: 독립적인 새 쿼리 생성\n- 이전 대화가 있는 경우: 이전 SQL 패턴과 연관성 고려\n\n**출력 규칙:**\n- SQL만 반환, 세미콜론 필수\n- LIMIT 100 기본 적용\n- TIMESTAMP_MICROS(event_timestamp) 사용"
  },
  "user_prompt": {
    "content": "이전 대화:\n$conversation_context\n\n현재 질문: $question\n\n위 컨텍스트를 고려하여 적절한 BigQuery SQL을 생성해주세요.",
    "variables": ["conversation_context", "question"]
  }
}
```

#### Data Analysis 템플릿 통합
```json
{
  "system_prompt": {
    "content": "데이터 분석 전문가로서 주어진 데이터를 분석하고 통찰력 있는 인사이트를 제공해주세요.\n\n**컨텍스트 처리 규칙:**\n- 이전 대화가 '[이전 대화 없음]'인 경우: 독립적인 새 분석 수행\n- 이전 대화가 있는 경우: 이전 분석과의 연관성, 트렌드 변화, 비교 분석 고려\n\n**분석 관점:**\n- 데이터의 주요 특징과 패턴\n- 비즈니스 인사이트\n- 액션 아이템 제안\n- 추가 분석 방향 제시"
  },
  "user_prompt": {
    "content": "이전 대화:\n$conversation_context\n\n현재 데이터:\n$data_context\n\n사용자 질문: $question\n\n위 정보를 종합하여 데이터 분석을 수행해주세요.",
    "variables": ["conversation_context", "data_context", "question"]
  }
}
```

### 4. 구현 변경사항

#### LLM Client 수정
```python
class AnthropicLLMClient(BaseLLMClient):
    
    def _normalize_conversation_context(self, conversation_context: List[Dict] = None) -> str:
        """컨텍스트 정규화 - 항상 문자열 반환"""
        if not conversation_context or len(conversation_context) == 0:
            return "[이전 대화 없음]"
        
        return self._format_conversation_context(conversation_context)
    
    def _execute_unified_prompting(self, 
                                 category: str,
                                 input_data: Dict[str, Any],
                                 conversation_context: List[Dict] = None,
                                 context_processor: callable = None) -> dict:
        """통합 프롬프팅 실행"""
        try:
            # 컨텍스트 정규화
            normalized_context = self._normalize_conversation_context(conversation_context)
            
            # 단일 템플릿 사용
            system_prompt = prompt_manager.get_prompt(
                category=category,
                template_name='system_prompt',
                conversation_context=normalized_context,
                **input_data
            )
            
            user_prompt = prompt_manager.get_prompt(
                category=category,
                template_name='user_prompt',
                conversation_context=normalized_context,
                **input_data
            )
            
            # 토큰 수 조정 (동적)
            max_tokens = self._calculate_dynamic_tokens(category, normalized_context)
            
            # Claude API 호출
            response = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=max_tokens,
                system=system_prompt,
                messages=[{"role": "user", "content": user_prompt}]
            )
            
            response_text = response.content[0].text.strip()
            return self._post_process_response(category, response_text, normalized_context)
            
        except Exception as e:
            logger.error(f"❌ 통합 프롬프팅 오류 ({category}): {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _calculate_dynamic_tokens(self, category: str, context: str) -> int:
        """컨텍스트 유무에 따른 동적 토큰 수 계산"""
        base_tokens = {
            'classification': 300,
            'sql_generation': 1200,
            'data_analysis': 1200
        }
        
        # 컨텍스트가 있으면 토큰 수 증가
        if context != "[이전 대화 없음]":
            return base_tokens.get(category, 400) + 100
        
        return base_tokens.get(category, 400)
```

### 5. 마이그레이션 계획

#### 단계별 구현
1. **1단계**: 새로운 통합 템플릿 작성
2. **2단계**: `_execute_unified_prompting` 메서드 구현
3. **3단계**: 기존 메서드들을 통합 메서드로 교체
4. **4단계**: 기존 중복 템플릿 제거
5. **5단계**: 테스트 및 검증

#### 호환성 보장
- 기존 API 인터페이스 유지
- 점진적 마이그레이션으로 안정성 확보
- 롤백 가능한 구조 유지

### 6. 장점

#### 코드 단순화
- 조건부 템플릿 선택 로직 제거
- 중복 템플릿 제거
- 유지보수성 향상

#### 일관성 확보
- 모든 요청이 동일한 템플릿 구조 사용
- 컨텍스트 처리 로직 표준화
- 프롬프트 품질 일관성

#### 확장성 개선
- 새로운 카테고리 추가 시 단일 템플릿만 작성
- 컨텍스트 처리 로직 재사용
- 프롬프트 엔지니어링 효율성

### 7. 성능 고려사항

#### 동적 토큰 할당 상세 설명

**토큰 할당 전략**
```python
def _calculate_dynamic_tokens(self, category: str, context: str) -> int:
    """
    컨텍스트 길이와 카테고리에 따른 지능형 토큰 할당
    """
    # 기본 토큰 설정
    base_tokens = {
        'classification': 300,     # 분류는 짧은 JSON 응답
        'sql_generation': 1200,    # SQL은 복잡한 쿼리 가능
        'data_analysis': 1200,     # 분석은 상세한 설명 필요
        'guide_request': 800,      # 가이드는 중간 길이
        'metadata_request': 600    # 메타데이터는 구조화된 응답
    }
    
    base = base_tokens.get(category, 400)
    
    # 컨텍스트 길이에 따른 추가 토큰
    if context == "[이전 대화 없음]":
        return base
    
    # 컨텍스트 길이 측정 (대략적)
    context_length = len(context.split())
    
    if context_length < 50:
        context_bonus = 50      # 짧은 컨텍스트
    elif context_length < 200:
        context_bonus = 100     # 중간 컨텍스트  
    else:
        context_bonus = 200     # 긴 컨텍스트
    
    # 카테고리별 컨텍스트 민감도
    context_multiplier = {
        'classification': 0.5,    # 분류는 컨텍스트 영향 적음
        'sql_generation': 1.0,    # SQL은 컨텍스트 중요
        'data_analysis': 1.5,     # 분석은 컨텍스트 매우 중요
        'guide_request': 0.7,
        'metadata_request': 0.3
    }
    
    multiplier = context_multiplier.get(category, 1.0)
    final_bonus = int(context_bonus * multiplier)
    
    return min(base + final_bonus, 2000)  # 최대 2000 토큰 제한
```

**토큰 효율성 분석**
- **컨텍스트 없는 경우**: 기본 토큰만 사용하여 비용 최적화
- **컨텍스트 있는 경우**: 필요한 만큼만 추가 할당하여 과도한 토큰 사용 방지
- **카테고리별 최적화**: 각 작업의 특성에 맞는 토큰 할당

**예상 토큰 사용량 변화**
```
현재 방식:
- 컨텍스트 없음: 300 토큰 (classification)
- 컨텍스트 있음: 400 토큰 (classification_with_context)

통합 후:
- 컨텍스트 없음: 300 토큰 (변화 없음)
- 짧은 컨텍스트: 325 토큰 (25 토큰 추가)
- 긴 컨텍스트: 400 토큰 (기존과 동일)
```

#### 토큰 사용량 최적화
- 빈 컨텍스트 메시지는 최소 토큰만 사용 (약 4-5 토큰)
- 동적 할당으로 불필요한 토큰 낭비 방지
- 카테고리별 특성을 고려한 정밀한 토큰 관리
- 전체적으로 토큰 사용량 안정화 및 비용 효율성 확보

#### 응답 품질
- 프롬프트 내에서 컨텍스트 유무 명시
- LLM이 적절히 상황 판단하여 응답
- 품질 저하 없이 구조 단순화

### 8. 테스트 전략

#### 회귀 테스트
- 기존 기능 동작 검증
- 컨텍스트 있는/없는 경우 모두 테스트
- 분류 정확도 유지 확인

#### 성능 테스트
- 토큰 사용량 모니터링
- 응답 시간 측정
- 품질 메트릭 비교

### 9. 결론

빈 컨텍스트 방식의 통합 전략은:
- 코드 복잡도를 크게 줄이고
- 유지보수성을 향상시키며
- 기능적 일관성을 확보하는

효과적인 리팩토링 방안입니다. 이를 통해 더 견고하고 확장 가능한 프롬프팅 시스템을 구축할 수 있습니다.