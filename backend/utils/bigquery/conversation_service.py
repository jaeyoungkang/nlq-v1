# backend/utils/bigquery/conversation_service.py
"""
BigQuery ëŒ€í™” ì„œë¹„ìŠ¤
ëŒ€í™” ì €ì¥/ì¡°íšŒ/ì‚­ì œ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©
"""

import os
import json
import logging
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, List
from google.cloud import bigquery
from google.cloud.exceptions import NotFound

logger = logging.getLogger(__name__)

class ConversationService:
    """BigQuery ëŒ€í™” ê´€ë¦¬ ì„œë¹„ìŠ¤ - ìŠ¤í‚¤ë§ˆ ì •ë¦¬ ê³„íš ì ìš©"""
    
    def __init__(self, project_id: str, location: str = "asia-northeast3"):
        """
        ConversationService ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            location: BigQuery ë¦¬ì „
        """
        self.project_id = project_id
        self.location = location
        try:
            self.client = bigquery.Client(project=project_id, location=location)
            logger.info(f"BigQuery ConversationService ì´ˆê¸°í™” ì™„ë£Œ: {project_id}")
        except Exception as e:
            logger.error(f"BigQuery ConversationService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    

    def save_complete_interaction(self, 
                                user_id: str, 
                                user_question: str,
                                assistant_answer: str, 
                                generated_sql: str = None,
                                query_result: dict = None,
                                context_message_ids: List[str] = None) -> Dict[str, Any]:
        """ì§ˆë¬¸-ë‹µë³€-ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì €ì¥ (í†µí•© êµ¬ì¡°)"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": False, "error": table_check_result['error']}
            
            message_id = str(uuid.uuid4())
            current_time = datetime.now(timezone.utc)
            
            # í†µí•©ëœ ë°ì´í„° êµ¬ì¡° - ê³„íšì„œ ê¸°ì¤€
            interaction_data = {
                'message_id': message_id,
                'user_id': user_id,
                'message_type': 'complete',  # ì§ˆë¬¸+ë‹µë³€ ì™„ì„±í˜•
                'message': user_question,     # ì‚¬ìš©ì ì§ˆë¬¸ë§Œ
                'response': assistant_answer, # AI ì‘ë‹µë§Œ (ë³„ë„ í•„ë“œ)
                'timestamp': current_time.isoformat(),
                'generated_sql': generated_sql,
                'query_id': str(uuid.uuid4()) if query_result else None,
                'context_message_ids': context_message_ids or []
            }
            
            # ì¿¼ë¦¬ ê²°ê³¼ ì§ì ‘ í¬í•¨
            if query_result:
                interaction_data.update({
                    'result_data': query_result.get('data', []),
                    'result_row_count': query_result.get('row_count', 0),
                    'result_status': 'success' if query_result.get('success') else 'error',
                    'error_message': query_result.get('error')
                })
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            table_ref = self.client.dataset(dataset_name).table('conversations')
            errors = self.client.insert_rows_json(table_ref, [interaction_data])
            
            if errors:
                logger.error(f"ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì‹¤íŒ¨: {errors}")
                return {"success": False, "error": f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {errors[0]}"}
            
            logger.info(f"ğŸ’¾ ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì™„ë£Œ: {message_id}")
            return {"success": True, "message_id": message_id, "message": "ìƒí˜¸ì‘ìš©ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
            
        except Exception as e:
            logger.error(f"ì™„ì „í•œ ìƒí˜¸ì‘ìš© ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e)}




    def get_conversation_with_context(self, user_id: str, limit: int = 10) -> Dict[str, Any]:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ëª¨ë“  ëŒ€í™” ê¸°ë¡ ì¡°íšŒ - JOIN ì—†ìŒ"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            table_id = f"{self.project_id}.{dataset_name}.conversations"
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„±
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                logger.info(f"í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ìƒì„± ì‹¤íŒ¨. ë¹ˆ ê²°ê³¼ ë°˜í™˜: {table_check_result.get('error')}")
                return {"success": True, "conversations": [], "count": 0}
            
            query = f"""
            SELECT 
                message_id,
                message as user_question,
                response as assistant_answer,
                generated_sql,
                result_data,
                result_row_count,
                result_status,
                timestamp,
                context_message_ids
            FROM `{table_id}`
            WHERE user_id = @user_id
            ORDER BY timestamp DESC
            LIMIT @limit
            """
            
            job_config = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ScalarQueryParameter('user_id', 'STRING', user_id),
                bigquery.ScalarQueryParameter('limit', 'INT64', limit)
            ])
            
            rows = list(self.client.query(query, job_config=job_config).result())
            
            conversations = []
            for row in rows:
                conv_data = {
                    "message_id": row.message_id,
                    "user_question": row.user_question,      # ê³„íšì„œ ê¸°ì¤€
                    "assistant_answer": row.assistant_answer, # ê³„íšì„œ ê¸°ì¤€
                    "generated_sql": row.generated_sql,
                    "result_row_count": row.result_row_count,
                    "result_status": row.result_status,
                    "timestamp": row.timestamp.isoformat() if row.timestamp else None,
                    "context_message_ids": list(row.context_message_ids) if row.context_message_ids else []
                }
                
                # result_dataê°€ ìˆìœ¼ë©´ í¬í•¨
                if row.result_data:
                    conv_data["result_data"] = row.result_data
                    
                conversations.append(conv_data)
            
            logger.info(f"ğŸ“š ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì™„ë£Œ: {len(conversations)}ê°œ (user_id: {user_id})")
            return {"success": True, "conversations": conversations, "count": len(conversations)}
            
        except Exception as e:
            logger.error(f"í†µí•© ëŒ€í™” ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e), "conversations": []}


    def _ensure_table_exists(self, dataset_name: str, table_name: str, create_method: callable) -> Dict[str, Any]:
        """í…Œì´ë¸” ì¡´ì¬ í™•ì¸ ë° ìƒì„± í—¬í¼"""
        try:
            # ë¨¼ì € ë°ì´í„°ì…‹ì´ ìˆëŠ”ì§€ í™•ì¸
            dataset_ref = self.client.dataset(dataset_name)
            try:
                self.client.get_dataset(dataset_ref)
            except NotFound:
                # ë°ì´í„°ì…‹ì´ ì—†ìœ¼ë©´ ìƒì„±
                logger.info(f"ë°ì´í„°ì…‹ {dataset_name} ì—†ìŒ. ìƒì„± ì‹œë„.")
                dataset = bigquery.Dataset(dataset_ref)
                dataset.location = self.location
                try:
                    self.client.create_dataset(dataset)
                    logger.info(f"ë°ì´í„°ì…‹ {dataset_name} ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    if 'Already exists' not in str(e):
                        logger.error(f"ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
                        return {"success": False, "error": f"ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {str(e)}"}
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            table_ref = self.client.dataset(dataset_name).table(table_name)
            try:
                self.client.get_table(table_ref)
                return {"success": True, "action": "exists"}
            except NotFound:
                logger.info(f"í…Œì´ë¸” {table_name} ì—†ìŒ. ìƒì„± ì‹œë„.")
                result = create_method(dataset_name)
                # ë™ì‹œ ìƒì„±ìœ¼ë¡œ ì¸í•œ Already Exists ì—ëŸ¬ëŠ” ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                if not result['success'] and 'Already Exists' in result.get('error', ''):
                    logger.info(f"í…Œì´ë¸” {table_name} ì´ë¯¸ ì¡´ì¬í•¨ (ë™ì‹œ ìƒì„±ë¨)")
                    return {"success": True, "action": "exists"}
                return result
        except Exception as e:
            logger.error(f"í…Œì´ë¸” í™•ì¸/ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e)}

    def _create_conversations_table(self, dataset_name: str) -> Dict[str, Any]:
        """í†µí•© êµ¬ì¡°ì˜ conversations í…Œì´ë¸” ìƒì„±"""
        table_id = f"{self.project_id}.{dataset_name}.conversations"
        try:
            schema = [
                # ê¸°ë³¸ í•„ë“œ
                bigquery.SchemaField("message_id", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("user_id", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("message_type", "STRING", mode="REQUIRED"),
                bigquery.SchemaField("message", "STRING"),
                bigquery.SchemaField("response", "STRING"),  # AI ì‘ë‹µ ì „ìš© í•„ë“œ ì¶”ê°€
                bigquery.SchemaField("timestamp", "TIMESTAMP", mode="REQUIRED"),
                bigquery.SchemaField("generated_sql", "STRING"),
                bigquery.SchemaField("query_id", "STRING"),
                
                # í†µí•© êµ¬ì¡° - ê²°ê³¼ ë°ì´í„° ì»¬ëŸ¼ë“¤
                bigquery.SchemaField("result_data", "JSON"),
                bigquery.SchemaField("result_row_count", "INT64"),
                bigquery.SchemaField("result_status", "STRING"),
                bigquery.SchemaField("error_message", "STRING"),
                bigquery.SchemaField("context_message_ids", "STRING", mode="REPEATED")
            ]
            table = bigquery.Table(table_id, schema=schema)
            table.time_partitioning = bigquery.TimePartitioning(type_=bigquery.TimePartitioningType.DAY, field="timestamp")
            self.client.create_table(table)
            logger.info(f"í†µí•© êµ¬ì¡° í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {table_id}")
            return {"success": True, "action": "created"}
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨ {table_id}: {e}")
            return {"success": False, "error": str(e)}


    def get_user_conversations(self, user_id: str, limit: int = 50, offset: int = 0) -> Dict[str, Any]:
        """ì‚¬ìš©ìì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ëª©ë¡ ì¡°íšŒ - ë‹¨ì¼ ì“°ë ˆë“œ ëª¨ë¸"""
        try:
            dataset_name = os.getenv('CONVERSATION_DATASET', 'v1')
            conversations_table = f"{self.project_id}.{dataset_name}.conversations"
            
            table_check_result = self._ensure_table_exists(dataset_name, 'conversations', self._create_conversations_table)
            if not table_check_result['success']:
                return {"success": True, "conversations": [], "count": 0}
            
            query = f"""
            SELECT 
                MIN(timestamp) as start_time,
                MAX(timestamp) as last_time,
                COUNT(*) as message_count,
                ARRAY_AGG(
                    CASE WHEN message_type = 'user' THEN message ELSE NULL END IGNORE NULLS
                    ORDER BY timestamp 
                    LIMIT 1
                )[SAFE_OFFSET(0)] as first_message
            FROM `{conversations_table}`
            WHERE user_id = @user_id
            """
            job_config = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ScalarQueryParameter("user_id", "STRING", user_id)
            ])
            
            results = self.client.query(query, job_config=job_config).result()
            row = next(iter(results), None)
            
            conversations = []
            if row and row.message_count > 0:
                conversations = [{
                    "user_id": user_id,
                    "start_time": row.start_time.isoformat() if row.start_time else None,
                    "last_time": row.last_time.isoformat() if row.last_time else None,
                    "message_count": row.message_count,
                    "first_message": row.first_message or "ëŒ€í™” ì—†ìŒ"
                }]
            
            return {"success": True, "conversations": conversations, "count": len(conversations)}
        except Exception as e:
            logger.error(f"ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "error": str(e), "conversations": []}